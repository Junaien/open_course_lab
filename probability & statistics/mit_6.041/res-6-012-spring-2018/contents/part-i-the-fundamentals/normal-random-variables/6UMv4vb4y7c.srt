1
00:00:01,510 --> 00:00:05,240
We now introduce normal random
variables, which are also

2
00:00:05,240 --> 00:00:08,029
often called Gaussian
random variables.

3
00:00:08,029 --> 00:00:10,930
Normal random variables are
perhaps the most important

4
00:00:10,930 --> 00:00:13,070
ones in probability theory.

5
00:00:13,070 --> 00:00:16,650
They play a key role in the
theory of the subject, as we

6
00:00:16,650 --> 00:00:19,860
will see later in this class in
the context of the central

7
00:00:19,860 --> 00:00:21,300
limit theorem.

8
00:00:21,300 --> 00:00:25,330
They're also prevalent in
applications for two reasons.

9
00:00:25,330 --> 00:00:30,120
They have some nice analytical
properties, and they're are

10
00:00:30,120 --> 00:00:34,470
also the most common model
of random noise.

11
00:00:34,470 --> 00:00:37,950
In general, they are a good
model of noise or randomness

12
00:00:37,950 --> 00:00:41,860
whenever that noise is due to
the addition of many small

13
00:00:41,860 --> 00:00:45,520
independent noise terms, and
this is a very common

14
00:00:45,520 --> 00:00:46,945
situation in the real world.

15
00:00:50,080 --> 00:00:52,890
We define normal random
variables by specifying their

16
00:00:52,890 --> 00:00:56,660
PDFs, and we start with the
simplest case of the so-called

17
00:00:56,660 --> 00:00:58,210
standard normal.

18
00:00:58,210 --> 00:01:01,370
The standard normal is indicated
with this shorthand

19
00:01:01,370 --> 00:01:06,080
notation, and we will see
shortly why this notation is

20
00:01:06,080 --> 00:01:07,410
being used.

21
00:01:07,410 --> 00:01:09,970
It is defined in
terms of a PDF.

22
00:01:09,970 --> 00:01:13,610
This PDF is defined for
all values of x. x

23
00:01:13,610 --> 00:01:15,750
can be any real number.

24
00:01:15,750 --> 00:01:19,100
So this random variable
can take values

25
00:01:19,100 --> 00:01:20,900
anywhere on the real line.

26
00:01:20,900 --> 00:01:23,630
And the formula for the
PDF is this one.

27
00:01:23,630 --> 00:01:26,820
Let us try to understand
this formula.

28
00:01:26,820 --> 00:01:31,660
So we have the exponential of
negative x squared over 2.

29
00:01:31,660 --> 00:01:37,229
Now, if we are to plot the x
squared over 2 function, it

30
00:01:37,229 --> 00:01:46,100
has a shape of this form, and
it is centered at zero.

31
00:01:46,100 --> 00:01:50,700
But then we take the negative
exponential of this function.

32
00:01:50,700 --> 00:01:54,360
Now, when you take the negative
exponential, whenever

33
00:01:54,360 --> 00:01:57,410
this thing is big, the negative
exponential is going

34
00:01:57,410 --> 00:01:58,530
to be small.

35
00:01:58,530 --> 00:02:03,170
So the negative exponential
would be equal to 1 when x is

36
00:02:03,170 --> 00:02:04,470
equal to 0.

37
00:02:04,470 --> 00:02:08,690
But then as x increases,
because x squared also

38
00:02:08,690 --> 00:02:12,170
increases, the negative
exponential will fall off.

39
00:02:12,170 --> 00:02:17,060
And so we obtain a shape of this
kind, and symmetrically

40
00:02:17,060 --> 00:02:21,220
on the other side as well.

41
00:02:21,220 --> 00:02:23,850
And finally, there
is this constant.

42
00:02:23,850 --> 00:02:26,570
Where [is] this constant
coming from?

43
00:02:26,570 --> 00:02:31,050
Well there's a nice and not
completely straightforward

44
00:02:31,050 --> 00:02:35,430
calculus exercise that tells
us that the integral from

45
00:02:35,430 --> 00:02:39,350
minus infinity to plus infinity
of e to the negative

46
00:02:39,350 --> 00:02:47,860
x squared over 2, dx, is equal
to the square root of 2 pi.

47
00:02:47,860 --> 00:02:51,210
Now, we need a PDF to
integrates to 1.

48
00:02:51,210 --> 00:02:55,360
And so for this to happen, this
is the constant that we

49
00:02:55,360 --> 00:02:58,630
need to put in front of this
expression so that the

50
00:02:58,630 --> 00:03:02,330
integral becomes 1, and that
explains the presence of this

51
00:03:02,330 --> 00:03:04,570
particular constant.

52
00:03:04,570 --> 00:03:08,260
What is the mean of this
random variable?

53
00:03:08,260 --> 00:03:12,280
Well, x squared is symmetric
around 0, and for this reason,

54
00:03:12,280 --> 00:03:15,740
the PDF itself is symmetric
around 0.

55
00:03:15,740 --> 00:03:21,800
And therefore, by symmetry, the
mean has to be equal to 0.

56
00:03:21,800 --> 00:03:24,540
And that explains
this entry here.

57
00:03:24,540 --> 00:03:26,430
How about the variance?

58
00:03:26,430 --> 00:03:30,150
Well, to calculate the variance,
you need to solve a

59
00:03:30,150 --> 00:03:31,930
calculus problem again.

60
00:03:31,930 --> 00:03:33,960
You need to integrate
by parts.

61
00:03:36,890 --> 00:03:41,380
And after you carry out the
calculation, then you find

62
00:03:41,380 --> 00:03:46,090
that the variance is equal to
1, and that explains this

63
00:03:46,090 --> 00:03:50,800
entry here in the notation
that we have been using.

64
00:03:50,800 --> 00:03:54,329
Let us now define general
normal random variables.

65
00:03:54,329 --> 00:03:57,070
General normal random variables
are once more

66
00:03:57,070 --> 00:04:01,440
specified in terms of the
corresponding PDF, but this

67
00:04:01,440 --> 00:04:04,810
PDF is a little more
complicated, and it involves

68
00:04:04,810 --> 00:04:06,190
two parameters--

69
00:04:06,190 --> 00:04:10,950
mu and sigma squared,
where sigma is a

70
00:04:10,950 --> 00:04:13,760
given positive parameter.

71
00:04:13,760 --> 00:04:19,050
Once more, it will have a bell
shape, but this bell is no

72
00:04:19,050 --> 00:04:23,150
longer symmetric around 0, and
there is some control over the

73
00:04:23,150 --> 00:04:25,060
width of it.

74
00:04:25,060 --> 00:04:29,610
Let us understand the form of
this PDF by focusing first on

75
00:04:29,610 --> 00:04:31,710
the exponent, exactly
as we did for the

76
00:04:31,710 --> 00:04:34,060
standard normal case.

77
00:04:34,060 --> 00:04:42,416
The exponent is a quadratic, and
that quadratic is centered

78
00:04:42,416 --> 00:04:46,290
at x equal to mu.

79
00:04:46,290 --> 00:04:49,750
So it vanishes when x
is equal to mu, and

80
00:04:49,750 --> 00:04:51,980
becomes positive elsewhere.

81
00:04:51,980 --> 00:04:55,340
Then we take the negative
exponential of this quadratic,

82
00:04:55,340 --> 00:05:00,640
and we obtain a function which
is largest at x equal to mu,

83
00:05:00,640 --> 00:05:05,440
and falls off as we go
further away from mu.

84
00:05:08,530 --> 00:05:11,880
What is the mean of this
random variable?

85
00:05:11,880 --> 00:05:16,550
Since this term is symmetric
around mu, the PDF is also

86
00:05:16,550 --> 00:05:20,770
symmetric around mu, and
therefore, the mean is also

87
00:05:20,770 --> 00:05:22,660
equal to mu.

88
00:05:22,660 --> 00:05:24,500
How about the variance?

89
00:05:24,500 --> 00:05:25,780
It turns out--

90
00:05:25,780 --> 00:05:28,620
and this is a calculus exercise
that we will omit--

91
00:05:28,620 --> 00:05:32,800
that the variance of this PDF
is equal to sigma squared.

92
00:05:32,800 --> 00:05:34,909
And this explains this
notation here.

93
00:05:34,909 --> 00:05:37,610
We're dealing with a normal that
has a mean of mu and a

94
00:05:37,610 --> 00:05:39,700
variance of sigma squared.

95
00:05:39,700 --> 00:05:43,380
To get a little bit of
understanding of the role of

96
00:05:43,380 --> 00:05:48,930
sigma in the form of this PDF,
let us consider the case where

97
00:05:48,930 --> 00:05:52,680
sigma is small, and see how the

98
00:05:52,680 --> 00:05:54,950
picture is going to change.

99
00:05:54,950 --> 00:05:59,890
When sigma is small, and we
plot the quadratic, sigma

100
00:05:59,890 --> 00:06:05,260
being small means that this
quadratic becomes larger, so

101
00:06:05,260 --> 00:06:10,290
it rises faster, so we get
a narrower quadratic.

102
00:06:10,290 --> 00:06:15,340
And in that case, the negative
exponential is going to fall

103
00:06:15,340 --> 00:06:18,920
off much faster.

104
00:06:18,920 --> 00:06:25,270
So when sigma is small, the PDF
that we get is a narrower

105
00:06:25,270 --> 00:06:31,370
PDF, and that reflects itself
into the property that the

106
00:06:31,370 --> 00:06:33,765
variance will also be smaller.

107
00:06:37,710 --> 00:06:40,650
An important property of normal
random variables is

108
00:06:40,650 --> 00:06:43,690
that they behave very nicely
when you form linear

109
00:06:43,690 --> 00:06:45,090
functions of them.

110
00:06:45,090 --> 00:06:48,280
And this is one of the reasons
why they're analytically

111
00:06:48,280 --> 00:06:51,450
tractable and analytically
very convenient.

112
00:06:51,450 --> 00:06:52,890
Here is what I mean.

113
00:06:52,890 --> 00:06:55,620
Let us start with a normal
random variable with a given

114
00:06:55,620 --> 00:06:58,810
mean and variance, and let us
form a linear function of that

115
00:06:58,810 --> 00:07:00,330
random variable.

116
00:07:00,330 --> 00:07:02,170
What is the mean of Y?

117
00:07:02,170 --> 00:07:05,060
Well, we know what it is.

118
00:07:05,060 --> 00:07:07,280
We have a linear function
of a random variable.

119
00:07:07,280 --> 00:07:10,600
The mean is going to be a times
the expected value of X,

120
00:07:10,600 --> 00:07:13,700
which is mu plus b.

121
00:07:13,700 --> 00:07:16,270
What is the variance of Y?

122
00:07:16,270 --> 00:07:19,030
We know what is the variance
of a linear function of a

123
00:07:19,030 --> 00:07:19,750
random variable.

124
00:07:19,750 --> 00:07:23,570
It is a squared times the
variance of X, which in our

125
00:07:23,570 --> 00:07:25,700
case is sigma squared.

126
00:07:25,700 --> 00:07:29,130
So there's nothing new so far,
but there is an additional

127
00:07:29,130 --> 00:07:30,435
important fact.

128
00:07:30,435 --> 00:07:34,590
The random variable Y, of
course, has the mean and

129
00:07:34,590 --> 00:07:38,080
variance that we know it should
have, but there is an

130
00:07:38,080 --> 00:07:39,500
additional fact--

131
00:07:39,500 --> 00:07:44,150
namely, that Y is a normal
random variable.

132
00:07:44,150 --> 00:07:50,080
So normality is preserved when
we form linear functions.

133
00:07:50,080 --> 00:07:52,440
There's one special case that's
we need to pay some

134
00:07:52,440 --> 00:07:53,780
attention to.

135
00:07:53,780 --> 00:07:56,750
Suppose that a is equal to 0.

136
00:07:56,750 --> 00:08:01,250
In this case, the random
variable Y is just equal to b.

137
00:08:01,250 --> 00:08:03,430
It's a constant random
variable.

138
00:08:03,430 --> 00:08:05,840
It does not have a PDF.

139
00:08:05,840 --> 00:08:10,790
It is a degenerate discrete
random variable.

140
00:08:10,790 --> 00:08:16,000
So could this fact be correct
that Y is also normal?

141
00:08:16,000 --> 00:08:19,980
Well, we'll adopt this
as [a] convention.

142
00:08:19,980 --> 00:08:25,420
When we have a discrete random
variable, which is constant,

143
00:08:25,420 --> 00:08:27,080
it takes a constant value.

144
00:08:27,080 --> 00:08:30,630
We can think of this as a
special degenerate case of the

145
00:08:30,630 --> 00:08:37,179
normal with mean equal to b and
with variance equal to 0.

146
00:08:37,179 --> 00:08:42,070
Even though it is discrete, not
continuous, we will still

147
00:08:42,070 --> 00:08:45,690
think of it as a degenerate
type of a normal random

148
00:08:45,690 --> 00:08:49,240
variable, and by adopting this
convention, then it will

149
00:08:49,240 --> 00:08:52,640
always be true that a linear
function of a normal random

150
00:08:52,640 --> 00:08:58,710
variable is normal, even
if a is equal to 0.

151
00:08:58,710 --> 00:09:01,080
Now that we have the definition
and some properties

152
00:09:01,080 --> 00:09:04,140
of normal random variables, the
next question is whether

153
00:09:04,140 --> 00:09:07,730
we can calculate probabilities
associated with

154
00:09:07,730 --> 00:09:09,410
normal random variables.

155
00:09:09,410 --> 00:09:11,320
This will be the subject
of the next segment.